# BERTSCORE: EVALUATING TEXT GENERATION WITH BERT - COMP6248
This project is the COMP6248 Reproducibility Challenge for the University of Southampton. The Reproducibility ICLR is BERTSCORE: EVALUATING TEXT GENERATION WITH BERT.
# Experiment Design
## Pre-trained Models
* Bert-base-uncased
* Bert-large-uncased
* Bert-base-cased-mrpc
* Roberta-base
* Roberta-large
* XLNet-base-cased
* XLNet-base-large
* XLM-mlm-en-2048
* XLM-mlm-100-1280
## Training Data
The training data is downloaded from WMT18. It is the monolingual training data, including Czech(cs), German(de), English(en), Russian(ru), and Chinese(zh).  
Website address: https://statmt.org/wmt18/translation-task.html#download
## BERTScore:
Website: https://github.com/Tiiiger/bert_score
